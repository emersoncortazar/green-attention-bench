{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f386a856-06e1-4bd7-86e9-86731b5c5b91",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m MAX_TOKENS = \u001b[32m128\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Get the EOS token id from the loaded model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m EOS_ID = \u001b[43mllm\u001b[49m.token_eos()\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEOS token id:\u001b[39m\u001b[33m\"\u001b[39m, EOS_ID)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mban_eos_logits_processor\u001b[39m(input_ids, logits):\n",
      "\u001b[31mNameError\u001b[39m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "# --- Benchmark controls ---\n",
    "MAX_TOKENS = 128\n",
    "\n",
    "# Get the EOS token id from the loaded model\n",
    "EOS_ID = llm.token_eos()\n",
    "print(\"EOS token id:\", EOS_ID)\n",
    "\n",
    "def ban_eos_logits_processor(input_ids, logits):\n",
    "    \"\"\"\n",
    "    llama-cpp-python logits_processor hook:\n",
    "    - input_ids: array of token ids so far\n",
    "    - logits: array of logits for next token\n",
    "    We set EOS logit to -inf so generation won't end early.\n",
    "    \"\"\"\n",
    "    # logits can be numpy array; mutate in place\n",
    "    logits[EOS_ID] = -1e10\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "322582e6-7a44-4a1b-bfba-15d373d7d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    \"Write a continuous technical explanation of energy efficiency in AI inference. \"\n",
    "    \"Do not conclude. Keep expanding with details, examples, and tradeoffs.\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7b65f8-9793-4381-82b8-c2ac292fa157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_once():\n",
    "    process = psutil.Process()\n",
    "    mem_before = process.memory_info().rss / 1e6\n",
    "\n",
    "    t0 = time.time()\n",
    "    out = llm(\n",
    "        prompt,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        temperature=0.0,     # deterministic\n",
    "        top_p=1.0,           # disable nucleus sampling\n",
    "        top_k=0,             # no top-k restriction\n",
    "        repeat_penalty=1.0,  # keep neutral for benchmarking\n",
    "        logits_processor=[ban_eos_logits_processor],\n",
    "    )\n",
    "    t1 = time.time()\n",
    "\n",
    "    mem_after = process.memory_info().rss / 1e6\n",
    "\n",
    "    text = out[\"choices\"][0][\"text\"]\n",
    "    n = out[\"usage\"][\"completion_tokens\"]\n",
    "    elapsed = t1 - t0\n",
    "    tps = n / elapsed if elapsed > 0 else float(\"inf\")\n",
    "\n",
    "    return {\n",
    "        \"tokens\": n,\n",
    "        \"seconds\": elapsed,\n",
    "        \"toks_per_sec\": tps,\n",
    "        \"mem_delta_mb\": mem_after - mem_before,\n",
    "        \"text_tail\": text[-120:],  # last bit, useful for debugging\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b140a25-93a0-4cb5-a9b5-dd8eeadd76ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m results = []\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     r = \u001b[43mrun_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     results.append(r)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRun \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: tokens=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr[\u001b[33m'\u001b[39m\u001b[33mtokens\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  time=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr[\u001b[33m'\u001b[39m\u001b[33mseconds\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms  tok/s=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr[\u001b[33m'\u001b[39m\u001b[33mtoks_per_sec\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mrun_once\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m mem_before = process.memory_info().rss / \u001b[32m1e6\u001b[39m\n\u001b[32m      5\u001b[39m t0 = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m out = \u001b[43mllm\u001b[49m(\n\u001b[32m      7\u001b[39m     prompt,\n\u001b[32m      8\u001b[39m     max_tokens=MAX_TOKENS,\n\u001b[32m      9\u001b[39m     temperature=\u001b[32m0.0\u001b[39m,     \u001b[38;5;66;03m# deterministic\u001b[39;00m\n\u001b[32m     10\u001b[39m     top_p=\u001b[32m1.0\u001b[39m,           \u001b[38;5;66;03m# disable nucleus sampling\u001b[39;00m\n\u001b[32m     11\u001b[39m     top_k=\u001b[32m0\u001b[39m,             \u001b[38;5;66;03m# no top-k restriction\u001b[39;00m\n\u001b[32m     12\u001b[39m     repeat_penalty=\u001b[32m1.0\u001b[39m,  \u001b[38;5;66;03m# keep neutral for benchmarking\u001b[39;00m\n\u001b[32m     13\u001b[39m     logits_processor=[ban_eos_logits_processor],\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m t1 = time.time()\n\u001b[32m     17\u001b[39m mem_after = process.memory_info().rss / \u001b[32m1e6\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(3):\n",
    "    r = run_once()\n",
    "    results.append(r)\n",
    "    print(f\"Run {i+1}: tokens={r['tokens']}  time={r['seconds']:.2f}s  tok/s={r['toks_per_sec']:.2f}\")\n",
    "\n",
    "print(\"\\nToken counts:\", [r[\"tokens\"] for r in results])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1153b321-a77d-4ddb-af1b-6ea8c5f09c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
